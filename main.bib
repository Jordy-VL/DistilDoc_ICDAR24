@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia}) 
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@article{kim2021comparing,
  title   = {Comparing kullback-leibler divergence and mean squared error loss in knowledge distillation},
  author  = {Kim, Taehyeon and Oh, Jaehoon and Kim, NakYil and Cho, Sangwook and Yun, Se-Young},
  journal = {arXiv preprint arXiv:2105.08919},
  year    = {2021}
}

@article{yang2023knowledge,
  title   = {From Knowledge Distillation to Self-Knowledge Distillation: A Unified Approach with Normalized Loss and Customized Soft Labels},
  author  = {Yang, Zhendong and Zeng, Ailing and Li, Zhe and Zhang, Tianke and Yuan, Chun and Li, Yu},
  journal = {arXiv preprint arXiv:2303.13005},
  year    = {2023}
}

@article{yang2022vitkd,
  title   = {ViTKD: Practical Guidelines for ViT feature knowledge distillation},
  author  = {Yang, Zhendong and Li, Zhe and Zeng, Ailing and Li, Zexian and Yuan, Chun and Li, Yu},
  journal = {arXiv preprint arXiv:2209.02432},
  year    = {2022}
}

@article{amara2022bd,
  title   = {BD-KD: Balancing the Divergences for Online Knowledge Distillation},
  author  = {Amara, Ibtihel and Sepahvand, Nazanin and Meyer, Brett H and Gross, Warren J and Clark, James J},
  journal = {arXiv preprint arXiv:2212.12965},
  year    = {2022}
}

@article{mehta2021mobilevit,
  title   = {Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer},
  author  = {Mehta, Sachin and Rastegari, Mohammad},
  journal = {arXiv preprint arXiv:2110.02178},
  year    = {2021}
}

@inproceedings{SimKD,
  author    = {D. Chen and J. Mei and H. Zhang and C. Wang and Y. Feng and C. Chen},
  booktitle = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Knowledge Distillation with the Reused Teacher Classifier},
  year      = {2022},
  publisher = {IEEE Computer Society}
}

@article{dosovitskiy2020image,
  title   = {An image is worth 16x16 words: Transformers for image recognition at scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal = {arXiv preprint arXiv:2010.11929},
  year    = {2020}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  year    = {2017}
}

@inproceedings{liu2021swin,
  title     = {Swin transformer: Hierarchical vision transformer using shifted windows},
  author    = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
  year      = {2021}
}

@article{hinton2015distilling,
  title   = {Distilling the knowledge in a neural network},
  author  = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal = {arXiv preprint arXiv:1503.02531},
  year    = {2015}
}

@article{ba2014deep,
  title   = {Do deep nets really need to be deep?},
  author  = {Ba, Jimmy and Caruana, Rich},
  journal = {Advances in neural information processing systems},
  year    = {2014}
}

@article{romero2014fitnets,
  title   = {Fitnets: Hints for thin deep nets},
  author  = {Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal = {arXiv preprint arXiv:1412.6550},
  year    = {2014}
}

@inproceedings{chen2021distilling,
  title     = {Distilling knowledge via knowledge review},
  author    = {Chen, Pengguang and Liu, Shu and Zhao, Hengshuang and Jia, Jiaya},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2021}
}

@inproceedings{komodakis2017paying,
  title     = {Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer},
  author    = {Komodakis, Nikos and Zagoruyko, Sergey},
  booktitle = {ICLR},
  year      = {2017}
}

@inproceedings{chen2021cross,
  title     = {Cross-layer distillation with semantic calibration},
  author    = {Chen, Defang and Mei, Jian-Ping and Zhang, Yuan and Wang, Can and Wang, Zhe and Feng, Yan and Chen, Chun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2021}
}

@inproceedings{he2021distilling,
  title     = {Distilling virtual examples for long-tailed recognition},
  author    = {He, Yin-Yin and Wu, Jianxin and Wei, Xiu-Shen},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {235--244},
  year      = {2021}
}

@inproceedings{Zhao_2022_CVPR,
  author    = {Zhao, Borui and Cui, Quan and Song, Renjie and Qiu, Yiyu and Liang, Jiajun},
  title     = {Decoupled Knowledge Distillation},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022}
}

@article{bagherinezhad2018label,
  title   = {Label refinery: Improving imagenet classification through label progression},
  author  = {Bagherinezhad, Hessam and Horton, Maxwell and Rastegari, Mohammad and Farhadi, Ali},
  journal = {arXiv preprint arXiv:1805.02641},
  year    = {2018}
}

@inproceedings{zhang2019your,
  title     = {Be your own teacher: Improve the performance of convolutional neural networks via self distillation},
  author    = {Zhang, Linfeng and Song, Jiebo and Gao, Anni and Chen, Jingwei and Bao, Chenglong and Ma, Kaisheng},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year      = {2019}
}

@inproceedings{park2019relational,
  title     = {Relational knowledge distillation},
  author    = {Park, Wonpyo and Kim, Dongju and Lu, Yan and Cho, Minsu},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2019}
}

@inproceedings{tian2019contrastive,
  title     = {Contrastive representation distillation},
  author    = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2019}
}

@inproceedings{chen2022knowledge,
  title     = {Knowledge distillation with the reused teacher classifier},
  author    = {Chen, Defang and Mei, Jian-Ping and Zhang, Hailin and Wang, Can and Feng, Yan and Chen, Chun},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year      = {2022}
}

@inproceedings{larson-etal-2023-evaluation,
  title     = {On Evaluation of Document Classification with {RVL}-{CDIP}},
  author    = {Larson, Stefan  and
               Lim, Gordon  and
               Leach, Kevin},
  booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = may,
  year      = {2023},
  address   = {Dubrovnik, Croatia},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.eacl-main.195},
  pages     = {2665--2678},
  abstract  = {The RVL-CDIP benchmark is widely used for measuring performance on the task of document classification. Despite its widespread use, we reveal several undesirable characteristics of the RVL-CDIP benchmark. These include (1) substantial amounts of label noise, which we estimate to be 8.1{\%} (ranging between 1.6{\%} to 16.9{\%} per document category); (2) presence of many ambiguous or multi-label documents; (3) a large overlap between test and train splits, which can inflate model performance metrics; and (4) presence of sensitive personally-identifiable information like US Social Security numbers (SSNs). We argue that there is a risk in using RVL-CDIP for benchmarking document classifiers, as its limited scope, presence of errors (state-of-the-art models now achieve accuracy error rates that are within our estimated label error rate), and lack of diversity make it less than ideal for benchmarking. We further advocate for the creation of a new document classification benchmark, and provide recommendations for what characteristics such a resource should include.}
}

@inproceedings{zhong2019publaynet,
  title        = {Publaynet: largest dataset ever for document layout analysis},
  author       = {Zhong, Xu and Tang, Jianbin and Yepes, Antonio Jimeno},
  booktitle    = {2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages        = {1015--1022},
  year         = {2019},
  organization = {IEEE}
}

@article{li2020docbank,
  title   = {DocBank: A benchmark dataset for document layout analysis},
  author  = {Li, Minghao and Xu, Yiheng and Cui, Lei and Huang, Shaohan and Wei, Furu and Li, Zhoujun and Zhou, Ming},
  journal = {arXiv preprint arXiv:2006.01038},
  year    = {2020}
}

@article{gou2021knowledge,
  title     = {Knowledge distillation: A survey},
  author    = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal   = {International Journal of Computer Vision},
  volume    = {129},
  pages     = {1789--1819},
  year      = {2021},
  publisher = {Springer}
}

@article{wang2022efficient,
  title   = {Efficient knowledge distillation from model checkpoints},
  author  = {Wang, Chaofei and Yang, Qisen and Huang, Rui and Song, Shiji and Huang, Gao},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {607--619},
  year    = {2022}
}

@inproceedings{moon2020confidence,
  title        = {Confidence-aware learning for deep neural networks},
  author       = {Moon, Jooyoung and Kim, Jihyo and Shin, Younghak and Hwang, Sangheum},
  booktitle    = {international conference on machine learning},
  pages        = {7034--7044},
  year         = {2020},
  organization = {PMLR}
}

@article{feng2022stop,
  title   = {Stop overcomplicating selective classification: Use max-logit},
  author  = {Feng, Leo and Ahmed, Mohamed Osama and Hajimirsadeghi, Hossein and Abdi, Amir},
  journal = {arXiv preprint arXiv:2206.09034},
  year    = {2022}
}

@inproceedings{zhang2020distilling,
  title     = {Distilling effective supervision from severe label noise},
  author    = {Zhang, Zizhao and Zhang, Han and Arik, Sercan O and Lee, Honglak and Pfister, Tomas},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {9294--9303},
  year      = {2020}
}

@article{huang2020self,
  title   = {Self-adaptive training: beyond empirical risk minimization},
  author  = {Huang, Lang and Zhang, Chao and Zhang, Hongyang},
  journal = {Advances in neural information processing systems},
  volume  = {33},
  pages   = {19365--19376},
  year    = {2020}
}

@inproceedings{harley2015evaluation,
  title        = {Evaluation of deep convolutional nets for document image classification and retrieval},
  author       = {Harley, Adam W and Ufkes, Alex and Derpanis, Konstantinos G},
  booktitle    = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
  pages        = {991--995},
  year         = {2015},
  organization = {IEEE}
}


@inproceedings{kumar2013unsupervised,
  title        = {Unsupervised classification of structurally similar document images},
  author       = {Kumar, Jayant and Doermann, David},
  booktitle    = {2013 12th International Conference on Document Analysis and Recognition},
  pages        = {1225--1229},
  year         = {2013},
  organization = {IEEE}
}

@inproceedings{larson2023labelnoise,
  title     = {On Evaluation of Document Classification with RVL-CDIP},
  author    = {Larson, Stefan and Lim, Gordon and Leach, Kevin},
  booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (EACL)},
  year      = {2023}
}

@inproceedings{larson2022evaluating,
  title     = {Evaluating Out-of-Distribution Performance on Document Image Classifiers},
  author    = {Larson, Stefan and Lim, Gordon and Ai, Yutong and Kuang, David and Leach, Kevin},
  booktitle = {Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year      = {2022}
}


@inproceedings{larson-etal-2023-evaluation,
  title     = {On Evaluation of Document Classification with {RVL}-{CDIP}},
  author    = {Larson, Stefan  and
               Lim, Gordon  and
               Leach, Kevin},
  booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = may,
  year      = {2023},
  address   = {Dubrovnik, Croatia},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.eacl-main.195},
  pages     = {2665--2678},
  abstract  = {The RVL-CDIP benchmark is widely used for measuring performance on the task of document classification. Despite its widespread use, we reveal several undesirable characteristics of the RVL-CDIP benchmark. These include (1) substantial amounts of label noise, which we estimate to be 8.1{\%} (ranging between 1.6{\%} to 16.9{\%} per document category); (2) presence of many ambiguous or multi-label documents; (3) a large overlap between test and train splits, which can inflate model performance metrics; and (4) presence of sensitive personally-identifiable information like US Social Security numbers (SSNs). We argue that there is a risk in using RVL-CDIP for benchmarking document classifiers, as its limited scope, presence of errors (state-of-the-art models now achieve accuracy error rates that are within our estimated label error rate), and lack of diversity make it less than ideal for benchmarking. We further advocate for the creation of a new document classification benchmark, and provide recommendations for what characteristics such a resource should include.}
}

@inproceedings{deng2009imagenet,
  title        = {Imagenet: A large-scale hierarchical image database},
  author       = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle    = {2009 IEEE conference on computer vision and pattern recognition},
  pages        = {248--255},
  year         = {2009},
  organization = {Ieee}
}

@inproceedings{lewis2006building,
  title     = {Building a test collection for complex document information processing},
  author    = {Lewis, David and Agam, Gady and Argamon, Shlomo and Frieder, Ophir and Grossman, David and Heard, Jefferson},
  booktitle = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages     = {665--666},
  year      = {2006}
}

@inproceedings{lin2014microsoft,
  title        = {Microsoft coco: Common objects in context},
  author       = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle    = {Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages        = {740--755},
  year         = {2014},
  organization = {Springer}
}

@inproceedings{li2020tablebank,
  title     = {Tablebank: Table benchmark for image-based table detection and recognition},
  author    = {Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming and Li, Zhoujun},
  booktitle = {Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages     = {1918--1925},
  year      = {2020}
}

@inproceedings{pfitzmann2022doclaynet,
  title     = {Doclaynet: A large human-annotated dataset for document-layout segmentation},
  author    = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter},
  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages     = {3743--3751},
  year      = {2022}
}

@inproceedings{li2022dit,
  title     = {Dit: Self-supervised pre-training for document image transformer},
  author    = {Li, Junlong and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Zhang, Cha and Wei, Furu},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  pages     = {3530--3539},
  year      = {2022}
}

@inproceedings{he2017mask,
  title     = {Mask r-cnn},
  author    = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {2961--2969},
  year      = {2017}
}

@inproceedings{liu2022swin,
  title     = {Swin transformer v2: Scaling up capacity and resolution},
  author    = {Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {12009--12019},
  year      = {2022}
}


@inproceedings{vanlandeghem2023document,
  title     = {{Document Understanding Dataset and Evaluation (DUDE)}},
  author    = {Van Landeghem, Jordy and Rub\`{e}n Tito and {\L}ukasz 
               Borchmann and 
               Micha{\l} Pietruszka and Pawel Joziak and Rafal Powalski and Dawid 
               Jurkiewicz 
               and Mickael Coustaty and Bertrand Ackaert and Ernest Valveny and Matthew 
               B. Blaschko and Marie-Francine Moens and Tomasz Stanislawek},
  year      = {2023},
  booktitle = {International Conference on Computer Vision}
}

@article{geifman2017selective,
  title   = {Selective classification for deep neural networks},
  author  = {Geifman, Yonatan and El-Yaniv, Ran},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@inproceedings{jaeger2023a,
  title     = {A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification},
  author    = {Paul F Jaeger and Carsten Tim L{\"u}th and Lukas Klein and Till J. Bungert},
  booktitle = {International Conference on Learning Representations},
  year      = {2023},
  url       = {https://openreview.net/forum?id=YnkGMIh0gvX}
}

@inproceedings{quinonero2005evaluating,
  title        = {Evaluating predictive uncertainty challenge},
  author       = {Quinonero-Candela, Joaquin and Rasmussen, Carl Edward and Sinz, Fabian and Bousquet, Olivier and Sch{\"o}lkopf, Bernhard},
  booktitle    = {Machine Learning Challenges Workshop},
  pages        = {1--27},
  year         = {2005},
  organization = {Springer}
}

@inproceedings{naeini2015obtaining,
  title     = {Obtaining well calibrated probabilities using {Bayesian} binning},
  author    = {Naeini, Mahdi Pakdaman and Cooper, Gregory and Hauskrecht, Milos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {29},
  number    = {1},
  year      = {2015}
}

@inproceedings{niculescu2005predicting,
  title     = {Predicting good probabilities with supervised learning},
  author    = {Niculescu-Mizil, Alexandru and Caruana, Rich},
  booktitle = {Proceedings of the 22nd International Conference on Machine learning},
  pages     = {625--632},
  year      = {2005}
}
	
@inproceedings{guo2017calibration,
  author    = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
  title     = {On Calibration of Modern Neural Networks},
  year      = {2017},
  abstract  = {Confidence calibration - the problem of predicting probability estimates representative of the true correctness likelihood - is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling - a single-parameter variant of Platt Scaling - is surprisingly effective at calibrating predictions.},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
  pages     = {1321–1330},
  numpages  = {10},
  location  = {Sydney, NSW, Australia},
  series    = {ICML'17}
}

@inproceedings{kang2014convolutional,
  title        = {Convolutional neural networks for document image classification},
  author       = {Kang, Le and Kumar, Jayant and Ye, Peng and Li, Yi and Doermann, David},
  booktitle    = {2014 22nd international conference on pattern recognition},
  pages        = {3168--3172},
  year         = {2014},
  organization = {IEEE}
}

@article{wang2023layout,
  title   = {Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering},
  author  = {Wang, Wenjin and Li, Yunhao and Ou, Yixin and Zhang, Yin},
  journal = {arXiv preprint arXiv:2306.00526},
  year    = {2023}
}

@inproceedings{liao2023doctr,
  title     = {DocTr: Document transformer for structured information extraction in documents},
  author    = {Liao, Haofu and RoyChowdhury, Aruni and Li, Weijian and Bansal, Ankan and Zhang, Yuting and Tu, Zhuowen and Satzoda, Ravi Kumar and Manmatha, R and Mahadevan, Vijay},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {19584--19594},
  year      = {2023}
}

@inproceedings{luo2023geolayoutlm,
  title     = {GeoLayoutLM: Geometric Pre-training for Visual Information Extraction},
  author    = {Luo, Chuwei and Cheng, Changxu and Zheng, Qi and Yao, Cong},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {7092--7101},
  year      = {2023}
}


@article{binmakhashen2019document,
  title     = {Document layout analysis: a comprehensive survey},
  author    = {Binmakhashen, Galal M and Mahmoud, Sabri A},
  journal   = {ACM Computing Surveys (CSUR)},
  volume    = {52},
  number    = {6},
  pages     = {1--36},
  year      = {2019},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{mathew2021docvqa,
  title     = {Docvqa: A dataset for vqa on document images},
  author    = {Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle = {Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages     = {2200--2209},
  year      = {2021}
}

@inproceedings{ding2022v,
  title     = {V-Doc: Visual questions answers with Documents},
  author    = {Ding, Yihao and Huang, Zhe and Wang, Runlin and Zhang, YanHang and Chen, Xianru and Ma, Yuzhong and Chung, Hyunsuk and Han, Soyeon Caren},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {21492--21498},
  year      = {2022}
}

@inproceedings{huang2022layoutlmv3,
  title     = {Layoutlmv3: Pre-training for document ai with unified text and image masking},
  author    = {Huang, Yupan and Lv, Tengchao and Cui, Lei and Lu, Yutong and Wei, Furu},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  pages     = {4083--4091},
  year      = {2022}
}

@article{gu2021unidoc,
  title   = {Unidoc: Unified pretraining framework for document understanding},
  author  = {Gu, Jiuxiang and Kuen, Jason and Morariu, Vlad I and Zhao, Handong and Jain, Rajiv and Barmpalios, Nikolaos and Nenkova, Ani and Sun, Tong},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  pages   = {39--50},
  year    = {2021}
}

@inproceedings{antonacopoulos2009realistic,
  title        = {A realistic dataset for performance evaluation of document layout analysis},
  author       = {Antonacopoulos, Apostolos and Bridson, David and Papadopoulos, Christos and Pletschacher, Stefan},
  booktitle    = {2009 10th International Conference on Document Analysis and Recognition},
  pages        = {296--300},
  year         = {2009},
  organization = {IEEE}
}

@article{cui2021document,
  title   = {Document ai: Benchmarks, models and applications},
  author  = {Cui, Lei and Xu, Yiheng and Lv, Tengchao and Wei, Furu},
  journal = {arXiv preprint arXiv:2111.08609},
  year    = {2021}
}

@inproceedings{da2023vision,
  title     = {Vision Grid Transformer for Document Layout Analysis},
  author    = {Da, Cheng and Luo, Chuwei and Zheng, Qi and Yao, Cong},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {19462--19472},
  year      = {2023}
}

@inproceedings{van2023icdar,
  title        = {ICDAR 2023 Competition on Document UnderstanDing of Everything (DUDE)},
  author       = {Van Landeghem, Jordy and Tito, Rub{\`e}n and Borchmann, {\L}ukasz and Pietruszka, Micha{\l} and Jurkiewicz, Dawid and Powalski, Rafa{\l} and J{\'o}ziak, Pawe{\l} and Biswas, Sanket and Coustaty, Micka{\"e}l and Stanis{\l}awek, Tomasz},
  booktitle    = {International Conference on Document Analysis and Recognition},
  pages        = {420--434},
  year         = {2023},
  organization = {Springer}
}

@inproceedings{van2023document,
  title     = {Document understanding dataset and evaluation (DUDE)},
  author    = {Van Landeghem, Jordy and Tito, Rub{\`e}n and Borchmann, {\L}ukasz and Pietruszka, Micha{\l} and Joziak, Pawel and Powalski, Rafal and Jurkiewicz, Dawid and Coustaty, Micka{\"e}l and Anckaert, Bertrand and Valveny, Ernest and others},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {19528--19540},
  year      = {2023}
}

@inproceedings{mathew2022infographicvqa,
  title     = {Infographicvqa},
  author    = {Mathew, Minesh and Bagal, Viraj and Tito, Rub{\`e}n and Karatzas, Dimosthenis and Valveny, Ernest and Jawahar, CV},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages     = {1697--1706},
  year      = {2022}
}

@article{hsieh2023distilling,
  title   = {Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes},
  author  = {Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-Kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alexander and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas},
  journal = {arXiv preprint arXiv:2305.02301},
  year    = {2023}
}

@article{treviso2023efficient,
  title     = {Efficient methods for natural language processing: A survey},
  author    = {Treviso, Marcos and Lee, Ji-Ung and Ji, Tianchu and Aken, Betty van and Cao, Qingqing and Ciosici, Manuel R and Hassid, Michael and Heafield, Kenneth and Hooker, Sara and Raffel, Colin and others},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {11},
  pages     = {826--860},
  year      = {2023},
  publisher = {MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{van2023beyond,
  title   = {Beyond Document Page Classification: Design, Datasets, and Challenges},
  author  = {Van Landeghem, Jordy and Biswas, Sanket and Blaschko, Matthew B and Moens, Marie-Francine},
  journal = {arXiv preprint arXiv:2308.12896},
  year    = {2023}
}

@inproceedings{he2016deep,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
}

@article{li2021benchmarking,
  title   = {Benchmarking detection transfer learning with vision transformers},
  author  = {Li, Yanghao and Xie, Saining and Chen, Xinlei and Dollar, Piotr and He, Kaiming and Girshick, Ross},
  journal = {arXiv preprint arXiv:2111.11429},
  year    = {2021}
}

@inproceedings{li2022exploring,
  title        = {Exploring plain vision transformer backbones for object detection},
  author       = {Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
  booktitle    = {European Conference on Computer Vision},
  pages        = {280--296},
  year         = {2022},
  organization = {Springer}
}

@inproceedings{bao2022beit,
  title     = {{BE}iT: {BERT} Pre-Training of Image Transformers},
  author    = {Hangbo Bao and Li Dong and Songhao Piao and Furu Wei},
  booktitle = {International Conference on Learning Representations},
  year      = {2022},
  url       = {https://openreview.net/forum?id=p-BhZSz59o4}
}

@inproceedings{bhojanapalli2021understanding,
  title     = {Understanding robustness of transformers for image classification},
  author    = {Bhojanapalli, Srinadh and Chakrabarti, Ayan and Glasner, Daniel and Li, Daliang and Unterthiner, Thomas and Veit, Andreas},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
  pages     = {10231--10241},
  year      = {2021}
}

@inproceedings{tishby2015deep,
  title        = {Deep learning and the information bottleneck principle},
  author       = {Tishby, Naftali and Zaslavsky, Noga},
  booktitle    = {2015 ieee information theory workshop (itw)},
  pages        = {1--5},
  year         = {2015},
  organization = {IEEE}
}


@article{guo2021distilling,
  title   = {Distilling image classifiers in object detectors},
  author  = {Guo, Shuxuan and Alvarez, Jose M and Salzmann, Mathieu},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  pages   = {1036--1047},
  year    = {2021}
}

@inproceedings{zhao2022decoupled,
  title     = {Decoupled knowledge distillation},
  author    = {Zhao, Borui and Cui, Quan and Song, Renjie and Qiu, Yiyu and Liang, Jiajun},
  booktitle = {Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition},
  pages     = {11953--11962},
  year      = {2022}
}

@inproceedings{munirtowards,
  title     = {Towards Improving Calibration in Object Detection Under Domain Shift},
  author    = {Munir, Muhammad Akhtar and Khan, Muhammad Haris and Sarfraz, M Saquib and Ali, Mohsen},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2022}
}

@article{cordonnier2019relationship,
  title   = {On the relationship between self-attention and convolutional layers},
  author  = {Cordonnier, Jean-Baptiste and Loukas, Andreas and Jaggi, Martin},
  journal = {arXiv preprint arXiv:1911.03584},
  year    = {2019}
}
@article{zhu2023survey,
  title   = {A survey on model compression for large language models},
  author  = {Zhu, Xunyu and Li, Jian and Liu, Yong and Ma, Can and Wang, Weiping},
  journal = {arXiv preprint arXiv:2308.07633},
  year    = {2023}
}
% NAS citations
@article{liu2017hierarchical,
  title   = {Hierarchical representations for efficient architecture search},
  author  = {Liu, Hanxiao and Simonyan, Karen and Vinyals, Oriol and Fernando, Chrisantha and Kavukcuoglu, Koray},
  journal = {arXiv preprint arXiv:1711.00436},
  year    = {2017}
}

@inproceedings{cai2018efficient,
  title     = {Efficient architecture search by network transformation},
  author    = {Cai, Han and Chen, Tianyao and Zhang, Weinan and Yu, Yong and Wang, Jun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {32},
  number    = {1},
  year      = {2018}
}

@inproceedings{liu2018progressive,
  title     = {Progressive neural architecture search},
  author    = {Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin},
  booktitle = {Proceedings of the European conference on computer vision (ECCV)},
  pages     = {19--34},
  year      = {2018}
}
@inproceedings{pham2018efficient,
  title        = {Efficient neural architecture search via parameters sharing},
  author       = {Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle    = {International conference on machine learning},
  pages        = {4095--4104},
  year         = {2018},
  organization = {PMLR}
}
% quantization
@inproceedings{faraone2018syq,
  title     = {Syq: Learning symmetric quantization for efficient deep neural networks},
  author    = {Faraone, Julian and Fraser, Nicholas and Blott, Michaela and Leong, Philip HW},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {4300--4309},
  year      = {2018}
}

@inproceedings{cao2017deep,
  title     = {Deep visual-semantic quantization for efficient image retrieval},
  author    = {Cao, Yue and Long, Mingsheng and Wang, Jianmin and Liu, Shichen},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {1328--1337},
  year      = {2017}
}

@inproceedings{yuan2020central,
  title     = {Central similarity quantization for efficient image and video retrieval},
  author    = {Yuan, Li and Wang, Tao and Zhang, Xiaopeng and Tay, Francis EH and Jie, Zequn and Liu, Wei and Feng, Jiashi},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {3083--3092},
  year      = {2020}
}

@inproceedings{li2023vit,
  title     = {I-vit: Integer-only quantization for efficient vision transformer inference},
  author    = {Li, Zhikai and Gu, Qingyi},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {17065--17075},
  year      = {2023}
}

@article{hu2021lora,
  title   = {Lora: Low-rank adaptation of large language models},
  author  = {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal = {arXiv preprint arXiv:2106.09685},
  year    = {2021}
}

@article{dettmers2023qlora,
  title   = {Qlora: Efficient finetuning of quantized llms},
  author  = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal = {arXiv preprint arXiv:2305.14314},
  year    = {2023}
}

% pruning

@article{zhu2017prune,
  title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
  author={Zhu, Michael and Gupta, Suyog},
  journal={arXiv preprint arXiv:1710.01878},
  year={2017}
}

@article{liu2018rethinking,
  title={Rethinking the value of network pruning},
  author={Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor},
  journal={arXiv preprint arXiv:1810.05270},
  year={2018}
}

@inproceedings{gao2021network,
  title={Network pruning via performance maximization},
  author={Gao, Shangqian and Huang, Feihu and Cai, Weidong and Huang, Heng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9270--9280},
  year={2021}
}

% early exits

@article{zhou2020bert,
  title={Bert loses patience: Fast and robust inference with early exit},
  author={Zhou, Wangchunshu and Xu, Canwen and Ge, Tao and McAuley, Julian and Xu, Ke and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18330--18341},
  year={2020}
}

@inproceedings{xing2020early,
  title={Early exit or not: Resource-efficient blind quality enhancement for compressed images},
  author={Xing, Qunliang and Xu, Mai and Li, Tianyi and Guan, Zhenyu},
  booktitle={European Conference on Computer Vision},
  pages={275--292},
  year={2020},
  organization={Springer}
}

@inproceedings{phuong2019distillation,
  title={Distillation-based training for multi-exit architectures},
  author={Phuong, Mary and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1355--1364},
  year={2019}
}


@inproceedings{tito2021icdar,
  title={Icdar 2021 competition on document visual question answering},
  author={Tito, Rub{\`e}n and Mathew, Minesh and Jawahar, CV and Valveny, Ernest and Karatzas, Dimosthenis},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={635--649},
  year={2021},
  organization={Springer}
}

@article{li2022explanations,
  title={Explanations from large language models make small reasoners better},
  author={Li, Shiyang and Chen, Jianshu and Shen, Yelong and Chen, Zhiyu and Zhang, Xinlu and Li, Zekun and Wang, Hong and Qian, Jing and Peng, Baolin and Mao, Yi and others},
  journal={arXiv preprint arXiv:2210.06726},
  year={2022}
}


@inproceedings{wu2022region,
  title={A Region-based Document VQA},
  author={Wu, Xinya and Zheng, Duo and Wang, Ruonan and Sun, Jiashen and Hu, Minzhen and Feng, Fangxiang and Wang, Xiaojie and Jiang, Huixing and Yang, Fan},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4909--4920},
  year={2022}
}

@inproceedings{he23good,
  title={Do-GOOD: Towards distribution shift evaluation for pre-trained visual document understanding models.(2023)},
  author={HE, Jiabang and HU, Yi and WANG, Lei and XU, Xing and LIU, Ning and LIU, Hui},
  booktitle={SIGIR},
  volume={23},
  pages={23--27}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@inproceedings{aditya2019spatial,
  title={Spatial knowledge distillation to aid visual reasoning},
  author={Aditya, Somak and Saha, Rudra and Yang, Yezhou and Baral, Chitta},
  booktitle={2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={227--235},
  year={2019},
} 

@article{pistone1995infinite,
  title        = {{An infinite-dimensional geometric structure on the space of all the probability measures equivalent to a given one}},
  author       = {Pistone, Giovanni and Sempi, Carlo},
  year         = 1995,
  journal      = {The annals of statistics},
  publisher    = {JSTOR},
  pages        = {1543--1561}
}
  organization={IEEE}
}

@inproceedings{mirzadeh2020improved,
  title={Improved knowledge distillation via teacher assistant},
  author={Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Matsukawa, Akihiro and Ghasemzadeh, Hassan},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={5191--5198},
  year={2020}
}

@inproceedings{ahn2019variational,
  title={Variational information distillation for knowledge transfer},
  author={Ahn, Sungsoo and Hu, Shell Xu and Damianou, Andreas and Lawrence, Neil D and Dai, Zhenwen},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9163--9171},
  year={2019}
}

@inproceedings{heo2019knowledge,
  title={Knowledge transfer via distillation of activation boundaries formed by hidden neurons},
  author={Heo, Byeongho and Lee, Minsik and Yun, Sangdoo and Choi, Jin Young},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3779--3787},
  year={2019}
}

@inproceedings{yim2017gift,
  title={A gift from knowledge distillation: Fast optimization, network minimization and transfer learning},
  author={Yim, Junho and Joo, Donggyu and Bae, Jihoon and Kim, Junmo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4133--4141},
  year={2017}
}


@inproceedings{passalis2020heterogeneous,
  title={Heterogeneous knowledge distillation using information flow modeling},
  author={Passalis, Nikolaos and Tzelepi, Maria and Tefas, Anastasios},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2339--2348},
  year={2020}
}

@inproceedings{zhang2018deep,
  title={Deep mutual learning},
  author={Zhang, Ying and Xiang, Tao and Hospedales, Timothy M and Lu, Huchuan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4320--4328},
  year={2018}
}

@inproceedings{chen2020online,
  title={Online knowledge distillation with diverse peers},
  author={Chen, Defang and Mei, Jian-Ping and Wang, Can and Feng, Yan and Chen, Chun},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={3430--3437},
  year={2020}
}

@inproceedings{xu2020layoutlm,
  title={Layoutlm: Pre-training of text and layout for document image understanding},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1192--1200},
  year={2020}
}

@article{xu2020layoutlmv2,
  title={Layoutlmv2: Multi-modal pre-training for visually-rich document understanding},
  author={Xu, Yang and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wei, Furu and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Che, Wanxiang and others},
  journal={arXiv preprint arXiv:2012.14740},
  year={2020}
}


@inproceedings{li2021selfdoc,
  title={Selfdoc: Self-supervised document representation learning},
  author={Li, Peizhao and Gu, Jiuxiang and Kuen, Jason and Morariu, Vlad I and Zhao, Handong and Jain, Rajiv and Manjunatha, Varun and Liu, Hongfu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5652--5660},
  year={2021}
}

@article{shen2022vila,
  title={VILA: Improving structured content extraction from scientific PDFs using visual layout groups},
  author={Shen, Zejiang and Lo, Kyle and Wang, Lucy Lu and Kuehl, Bailey and Weld, Daniel S and Downey, Doug},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={376--392},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{saad2023pdftriage,
  title={PDFTriage: Question Answering over Long, Structured Documents},
  author={Saad-Falcon, Jon and Barrow, Joe and Siu, Alexa and Nenkova, Ani and Rossi, Ryan A and Dernoncourt, Franck},
  journal={arXiv preprint arXiv:2309.08872},
  year={2023}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{biten2019scene,
  title={Scene text visual question answering},
  author={Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Mar{\c{c}}al and Valveny, Ernest and Jawahar, CV and Karatzas, Dimosthenis},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  year={2019}
}

@article{chen2017learning,
  title={Learning efficient object detection models with knowledge distillation},
  author={Chen, Guobin and Choi, Wongun and Yu, Xiang and Han, Tony and Chandraker, Manmohan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{stanton2021does,
  title={Does knowledge distillation really work?},
  author={Stanton, Samuel and Izmailov, Pavel and Kirichenko, Polina and Alemi, Alexander A and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6906--6919},
  year={2021}
}

@inproceedings{you2017learning,
  title={Learning from multiple teacher networks},
  author={You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1285--1294},
  year={2017}
}

@inproceedings{haralick1994document,
  title={Document image understanding: Geometric and logical layout},
  author={Haralick},
  booktitle={1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
  pages={385--390},
  year={1994},
  organization={IEEE}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

%KIE

@inproceedings{jaume2019funsd,
  title={Funsd: A dataset for form understanding in noisy scanned documents},
  author={Jaume, Guillaume and Ekenel, Hazim Kemal and Thiran, Jean-Philippe},
  booktitle={2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)},
  volume={2},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@article{vsimsa2023docile,
  title={Docile benchmark for document information localization and extraction},
  author={{\v{S}}imsa, {\v{S}}t{\v{e}}p{\'a}n and {\v{S}}ulc, Milan and U{\v{r}}i{\v{c}}{\'a}{\v{r}}, Michal and Patel, Yash and Hamdi, Ahmed and Koci{\'a}n, Mat{\v{e}}j and Skalick{\`y}, Maty{\'a}{\v{s}} and Matas, Ji{\v{r}}{\'\i} and Doucet, Antoine and Coustaty, Micka{\"e}l and others},
  journal={arXiv preprint arXiv:2302.05658},
  year={2023}
}

@inproceedings{stanislawek2021kleister,
  title={Kleister: key information extraction datasets involving long documents with complex layouts},
  author={Stanis{\l}awek, Tomasz and Grali{\'n}ski, Filip and Wr{\'o}blewska, Anna and Lipi{\'n}ski, Dawid and Kaliska, Agnieszka and Rosalska, Paulina and Topolski, Bartosz and Biecek, Przemys{\l}aw},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={564--579},
  year={2021},
  organization={Springer}
}

@article{galil2023can,
  title={What can we learn from the selective prediction and uncertainty estimation performance of 523 imagenet classifiers},
  author={Galil, Ido and Dabbah, Mohammed and El-Yaniv, Ran},
  journal={arXiv preprint arXiv:2302.11874},
  year={2023}
}

@inproceedings{jain2019multimodal,
  title={Multimodal document image classification},
  author={Jain, Rajiv and Wigington, Curtis},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={71--77},
  year={2019},
  organization={IEEE}
}

@article{liu2021document,
  title={Document image classification: Progress over two decades},
  author={Liu, Li and Wang, Zhiyu and Qiu, Taorong and Chen, Qiu and Lu, Yue and Suen, Ching Y},
  journal={Neurocomputing},
  volume={453},
  pages={223--240},
  year={2021},
  publisher={Elsevier}
}

@article{gu2023knowledge,
  title={Knowledge Distillation of Large Language Models},
  author={Gu, Yuxian and Dong, Li and Wei, Furu and Huang, Minlie},
  journal={arXiv preprint arXiv:2306.08543},
  year={2023}
}

@article{biswas2021beyond,
  title={Beyond document object detection: instance-level segmentation of complex layouts},
  author={Biswas, Sanket and Riba, Pau and Llad{\'o}s, Josep and Pal, Umapada},
  journal={International Journal on Document Analysis and Recognition (IJDAR)},
  year={2021}
}

@inproceedings{vapnik1992principles,
	title={Principles of risk minimization for learning theory},
	author={Vapnik, Vladimir},
	booktitle={Advances in neural information processing systems},
	pages={831--838},
	year={1992}
}

@article{shimodaira2000improving,
	title={Improving predictive inference under covariate shift by weighting the log-likelihood function},
	author={Shimodaira, Hidetoshi},
	journal={Journal of Statistical Planning and Inference},
	volume={90},
	number={2},
	pages={227--244},
	year={2000},
	publisher={Elsevier}
}

@inproceedings{borchmann2021due,
  title={DUE: End-to-End Document Understanding Benchmark},
  author={Borchmann, {\L}ukasz and Pietruszka, Micha{\l} and Stanislawek, Tomasz and Jurkiewicz, Dawid and Turski, Micha{\l} and Szyndler, Karolina and Grali{\'n}ski, Filip},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}